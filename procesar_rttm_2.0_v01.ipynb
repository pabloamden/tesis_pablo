{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33230d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa as lib\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix,multilabel_confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.sparse import coo_matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "631af0ff",
   "metadata": {},
   "source": [
    "## Importar los rttm y convertirlos en un df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8afcc5f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se encontraron 3 posibles bases en C:\\Users\\pablo\\Documents\\CIIPME\\Pablo\\tesis_pablo\\transcripciones-segunda-vuelta\\random\n",
      "\n",
      "[AVISO] Salteando 'bautista-a1-nsb': falta archivo elan.\n",
      "[AVISO] Salteando 'bautistad-a1-nsb': falta archivo diar.\n",
      "Procesando: camilob-a1-nsm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "camilob-a1-nsm: Processing intervals (15 blocks): 100%|██████████| 180000/180000 [41:01<00:00, 73.11it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -> Guardado: outputs\\transcripciones-segunda-vuelta\\random\\camilob-a1-nsm_results.csv\n",
      "\n",
      "Archivo global: outputs\\transcripciones-segunda-vuelta\\random\\_all_results.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ============================================================\n",
    "# Config\n",
    "# ============================================================\n",
    "\n",
    "BASE_DIR = Path(\"transcripciones-segunda-vuelta/random\")\n",
    "OUT_DIR = Path(\"outputs/transcripciones-segunda-vuelta/random\")\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "STEP = 0.01  # tu resolución temporal\n",
    "\n",
    "# ============================================================\n",
    "# Helpers de lectura RTTM (tus funciones)\n",
    "# ============================================================\n",
    "def read_rttm(file_path):\n",
    "    columns = ['Type', 'File ID', 'Channel', 'Start Time', 'Duration', 'Ortho', 'Ortho1', 'SType', 'Conf']\n",
    "    df = pd.read_csv(file_path, delim_whitespace=True, header=None, names=columns)\n",
    "    df['Start Time'] = df['Start Time'].astype(float)\n",
    "    df['Duration'] = df['Duration'].astype(float)\n",
    "    df['Conf'] = df['Conf'].astype(float)\n",
    "    return df\n",
    "\n",
    "def read_rttm_diar(file_path):\n",
    "    columns = ['Type', 'File ID', 'Channel', 'Start Time', 'Duration', 'Ortho1', 'Ortho2', 'SType', 'Name1', 'Name2']\n",
    "    df = pd.read_csv(file_path, delim_whitespace=True, header=None, names=columns)\n",
    "    df['Start Time'] = df['Start Time'].astype(float)\n",
    "    df['Duration'] = df['Duration'].astype(float)\n",
    "    return df\n",
    "\n",
    "def merge_intervals(iv):\n",
    "    if not iv:\n",
    "        return iv\n",
    "    iv_sorted = sorted(iv, key=lambda x: x[0])\n",
    "    merged = [iv_sorted[0]]\n",
    "    for s, e in iv_sorted[1:]:\n",
    "        last_s, last_e = merged[-1]\n",
    "        if s <= last_e:  # solapado o contiguo\n",
    "            merged[-1] = (last_s, max(last_e, e))\n",
    "        else:\n",
    "            merged.append((s, e))\n",
    "    return merged\n",
    "\n",
    "# ============================================================\n",
    "# Preparar el mapeo de archivos: base -> {elan, diar}\n",
    "#   - \"elan\"  = *.rttm sin sufijo \"-diarization\"\n",
    "#   - \"diar\"  = *-diarization.rttm\n",
    "# ============================================================\n",
    "pairs = {}\n",
    "for f in BASE_DIR.glob(\"*.rttm\"):\n",
    "    fn = f.name\n",
    "    if fn.endswith(\"-diarization.rttm\"):\n",
    "        base = fn[:-len(\"-diarization.rttm\")]  # quita el sufijo\n",
    "        pairs.setdefault(base, {})[\"diar\"] = f\n",
    "    else:\n",
    "        base = fn[:-len(\".rttm\")]             # base sin extensión\n",
    "        pairs.setdefault(base, {})[\"elan\"] = f\n",
    "\n",
    "# ============================================================\n",
    "# Función que procesa un par (elan + diar) y devuelve df_results\n",
    "# ============================================================\n",
    "def process_pair(base_name, elan_path: Path, diar_path: Path, step=STEP):\n",
    "    # ---------------- Leer\n",
    "    df_rttm = read_rttm(elan_path)\n",
    "    df_rttm_diar = read_rttm_diar(diar_path)\n",
    "\n",
    "    # ---------------- Mapear SType -> STypeNew (Elan)\n",
    "    conditions = [\n",
    "        df_rttm[\"SType\"] == \"CHI\",\n",
    "        df_rttm[\"SType\"].str.startswith(\"F\"),\n",
    "        df_rttm[\"SType\"].str.startswith(\"M\"),\n",
    "        df_rttm[\"SType\"].str.startswith(\"UC\"),\n",
    "        df_rttm[\"SType\"].str.startswith(\"E\")\n",
    "    ]\n",
    "    choices = [\"KCHI\", \"FEM\", \"MAL\", \"OCH\", \"ELE\"]\n",
    "    df_rttm[\"STypeNew\"] = np.select(conditions, choices, default=df_rttm[\"SType\"])\n",
    "\n",
    "    # ---------------- STypeNew para diar (tal como en tu código)\n",
    "    df_rttm_diar[\"STypeNew\"] = df_rttm_diar[\"SType\"]\n",
    "\n",
    "    # ---------------- Tipificar 'Type' y columnas mínimas\n",
    "    df_rttm['Type'] = 'Elan'\n",
    "    df_rttm_diar['Type'] = 'Diar'\n",
    "\n",
    "    df_rttm = df_rttm[['Type', 'File ID', 'Start Time', 'Duration', 'STypeNew']]\n",
    "    df_rttm_diar = df_rttm_diar[['Type', 'File ID', 'Start Time', 'Duration', 'STypeNew']]\n",
    "\n",
    "    # ---------------- Concatenar ambos\n",
    "    df_both = pd.concat([df_rttm, df_rttm_diar], ignore_index=True)\n",
    "    df_both = df_both.dropna(subset=['STypeNew'])\n",
    "\n",
    "    # ---------------- End Time (acelera filtros)\n",
    "    if \"End Time\" not in df_both.columns:\n",
    "        df_both[\"End Time\"] = df_both[\"Start Time\"] + df_both[\"Duration\"]\n",
    "\n",
    "    # ---------------- Filtrar \"code\" en Elan para construir intervalos\n",
    "    #     (si no hay \"code\", se procesará 0 pasos)\n",
    "    df_rttm[\"Start Time\"] = pd.to_numeric(df_rttm[\"Start Time\"], errors=\"coerce\")\n",
    "    df_rttm[\"Duration\"] = pd.to_numeric(df_rttm[\"Duration\"], errors=\"coerce\")\n",
    "\n",
    "    df_code = (\n",
    "        df_rttm.loc[df_rttm[\"STypeNew\"].eq(\"code\"), [\"Start Time\", \"Duration\"]]\n",
    "               .dropna()\n",
    "               .query(\"`Duration` > 0\")\n",
    "               .sort_values(\"Start Time\", kind=\"stable\")\n",
    "    )\n",
    "\n",
    "    intervals = list(\n",
    "        df_code.apply(lambda r: (float(r[\"Start Time\"]), float(r[\"Start Time\"] + r[\"Duration\"])), axis=1)\n",
    "    )\n",
    "    intervals = merge_intervals(intervals)\n",
    "\n",
    "    # ---------------- Si no hay intervalos \"code\", devolvemos vacío con metadata\n",
    "    if not intervals:\n",
    "        return pd.DataFrame({\n",
    "            'Elan_KCHI': [], 'Elan_OCH': [], 'Elan_FEM': [], 'Elan_MAL': [], 'Elan_ELE': [],\n",
    "            'Diar_KCHI': [], 'Diar_OCH': [], 'Diar_FEM': [], 'Diar_MAL': [], 'Diar_SPEECH': []\n",
    "        })\n",
    "\n",
    "    # ---------------- Inicializar resultados\n",
    "    results = {\n",
    "        'Elan_KCHI': [], 'Elan_OCH': [], 'Elan_FEM': [], 'Elan_MAL': [], 'Elan_ELE': [],\n",
    "        'Diar_KCHI': [], 'Diar_OCH': [], 'Diar_FEM': [], 'Diar_MAL': [], 'Diar_SPEECH': []\n",
    "    }\n",
    "\n",
    "    # ---------------- Calcular total de pasos\n",
    "    total_steps = 0\n",
    "    for s, e in intervals:\n",
    "        if e > s:\n",
    "            total_steps += int(np.ceil((e - s) / step))\n",
    "\n",
    "    # ---------------- Iterar con barra de progreso\n",
    "    with tqdm(total=total_steps, desc=f\"{base_name}: Processing intervals ({len(intervals)} blocks)\") as pbar:\n",
    "        for s, e in intervals:\n",
    "            if e <= s:\n",
    "                continue\n",
    "            # Generamos una vista para reducir scans:\n",
    "            # (Esto aún es simple; si querés más performance se puede indexar por tiempo)\n",
    "            for i in np.arange(s, e, step):\n",
    "                for key in results.keys():\n",
    "                    type_name, stype_new = key.split('_', 1)  # 'Elan' / 'Diar', 'KCHI'/...\n",
    "                    has_any = (\n",
    "                        df_both[\n",
    "                            (df_both['Start Time'] <= i) &\n",
    "                            (df_both['End Time'] > i) &\n",
    "                            (df_both['STypeNew'] == stype_new) &\n",
    "                            (df_both['Type'] == type_name)\n",
    "                        ].shape[0] > 0\n",
    "                    )\n",
    "                    results[key].append(int(has_any))\n",
    "                pbar.update(1)\n",
    "\n",
    "    df_results = pd.DataFrame(results)\n",
    "    return df_results\n",
    "\n",
    "# ============================================================\n",
    "# Loop general sobre todos los pares encontrados\n",
    "# ============================================================\n",
    "all_outputs = []  # para concatenar si querés un único CSV global\n",
    "\n",
    "print(f\"Se encontraron {len(pairs)} posibles bases en {BASE_DIR.resolve()}\\n\")\n",
    "\n",
    "for base_name, d in pairs.items():\n",
    "    if \"elan\" not in d or \"diar\" not in d:\n",
    "        # Aviso si falta alguno de los dos archivos\n",
    "        faltante = \"elan\" if \"elan\" not in d else \"diar\"\n",
    "        print(f\"[AVISO] Salteando '{base_name}': falta archivo {faltante}.\")\n",
    "        continue\n",
    "\n",
    "    elan_path = d[\"elan\"]\n",
    "    diar_path = d[\"diar\"]\n",
    "\n",
    "    print(f\"Procesando: {base_name}\")\n",
    "    df_results = process_pair(base_name, elan_path, diar_path, step=STEP)\n",
    "\n",
    "    # Guardar cada resultado individual\n",
    "    out_file = OUT_DIR / f\"{base_name}_results.csv\"\n",
    "    df_results.to_csv(out_file, index=False)\n",
    "    print(f\" -> Guardado: {out_file}\")\n",
    "\n",
    "    # (Opcional) agregar metadata para concatenado global\n",
    "    if not df_results.empty:\n",
    "        df_results[\"name\"] = base_name\n",
    "        all_outputs.append(df_results)\n",
    "\n",
    "# ============================================================\n",
    "# (Opcional) Un único CSV global con todos los archivos\n",
    "# ============================================================\n",
    "if all_outputs:\n",
    "    df_all = pd.concat(all_outputs, ignore_index=True)\n",
    "#     df_all.to_csv(OUT_DIR / \"_all_results.csv\", index=False)\n",
    "    print(f\"\\nArchivo global: {OUT_DIR / '_all_results.csv'}\")\n",
    "else:\n",
    "    print(\"\\nNo hubo resultados (posiblemente no hay intervalos 'code' en Elan).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "82835ea7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CHI', 'FA1', 'code', 'MC1', 'MA1', 'EE1', 'MC2', 'FC1', 'FA2', 'FA3', 'FA4', 'FA5', 'FA6', 'MC3', 'FA7', 'MA2', 'MC4', 'UC1']\n"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dc69f9b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>File ID</th>\n",
       "      <th>Channel</th>\n",
       "      <th>Start Time</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Ortho</th>\n",
       "      <th>Ortho1</th>\n",
       "      <th>SType</th>\n",
       "      <th>Conf</th>\n",
       "      <th>STypeNew</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SPEAKER</td>\n",
       "      <td>biancak-a2-nsb</td>\n",
       "      <td>1</td>\n",
       "      <td>123.88</td>\n",
       "      <td>0.65</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CHI</td>\n",
       "      <td>1.0</td>\n",
       "      <td>KCHI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SPEAKER</td>\n",
       "      <td>biancak-a2-nsb</td>\n",
       "      <td>1</td>\n",
       "      <td>140.27</td>\n",
       "      <td>4.26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CHI</td>\n",
       "      <td>1.0</td>\n",
       "      <td>KCHI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SPEAKER</td>\n",
       "      <td>biancak-a2-nsb</td>\n",
       "      <td>1</td>\n",
       "      <td>145.02</td>\n",
       "      <td>1.08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CHI</td>\n",
       "      <td>1.0</td>\n",
       "      <td>KCHI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SPEAKER</td>\n",
       "      <td>biancak-a2-nsb</td>\n",
       "      <td>1</td>\n",
       "      <td>149.05</td>\n",
       "      <td>0.64</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CHI</td>\n",
       "      <td>1.0</td>\n",
       "      <td>KCHI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SPEAKER</td>\n",
       "      <td>biancak-a2-nsb</td>\n",
       "      <td>1</td>\n",
       "      <td>151.03</td>\n",
       "      <td>0.98</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CHI</td>\n",
       "      <td>1.0</td>\n",
       "      <td>KCHI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>841</th>\n",
       "      <td>SPEAKER</td>\n",
       "      <td>biancak-a2-nsb</td>\n",
       "      <td>1</td>\n",
       "      <td>11512.75</td>\n",
       "      <td>0.57</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MC4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>842</th>\n",
       "      <td>SPEAKER</td>\n",
       "      <td>biancak-a2-nsb</td>\n",
       "      <td>1</td>\n",
       "      <td>12639.02</td>\n",
       "      <td>0.39</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MC4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>843</th>\n",
       "      <td>SPEAKER</td>\n",
       "      <td>biancak-a2-nsb</td>\n",
       "      <td>1</td>\n",
       "      <td>13297.77</td>\n",
       "      <td>0.39</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MC4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>844</th>\n",
       "      <td>SPEAKER</td>\n",
       "      <td>biancak-a2-nsb</td>\n",
       "      <td>1</td>\n",
       "      <td>13308.74</td>\n",
       "      <td>1.21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MC4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>845</th>\n",
       "      <td>SPEAKER</td>\n",
       "      <td>biancak-a2-nsb</td>\n",
       "      <td>1</td>\n",
       "      <td>11425.50</td>\n",
       "      <td>99.40</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>UC1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>OCH</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>846 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Type         File ID  Channel  Start Time  Duration  Ortho  Ortho1  \\\n",
       "0    SPEAKER  biancak-a2-nsb        1      123.88      0.65    NaN     NaN   \n",
       "1    SPEAKER  biancak-a2-nsb        1      140.27      4.26    NaN     NaN   \n",
       "2    SPEAKER  biancak-a2-nsb        1      145.02      1.08    NaN     NaN   \n",
       "3    SPEAKER  biancak-a2-nsb        1      149.05      0.64    NaN     NaN   \n",
       "4    SPEAKER  biancak-a2-nsb        1      151.03      0.98    NaN     NaN   \n",
       "..       ...             ...      ...         ...       ...    ...     ...   \n",
       "841  SPEAKER  biancak-a2-nsb        1    11512.75      0.57    NaN     NaN   \n",
       "842  SPEAKER  biancak-a2-nsb        1    12639.02      0.39    NaN     NaN   \n",
       "843  SPEAKER  biancak-a2-nsb        1    13297.77      0.39    NaN     NaN   \n",
       "844  SPEAKER  biancak-a2-nsb        1    13308.74      1.21    NaN     NaN   \n",
       "845  SPEAKER  biancak-a2-nsb        1    11425.50     99.40    NaN     NaN   \n",
       "\n",
       "    SType  Conf STypeNew  \n",
       "0     CHI   1.0     KCHI  \n",
       "1     CHI   1.0     KCHI  \n",
       "2     CHI   1.0     KCHI  \n",
       "3     CHI   1.0     KCHI  \n",
       "4     CHI   1.0     KCHI  \n",
       "..    ...   ...      ...  \n",
       "841   MC4   1.0      MAL  \n",
       "842   MC4   1.0      MAL  \n",
       "843   MC4   1.0      MAL  \n",
       "844   MC4   1.0      MAL  \n",
       "845   UC1   1.0      OCH  \n",
       "\n",
       "[846 rows x 10 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b9fd5a73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fd766881",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "biancak-a2-nsb\n",
      "Contenido de df_both:\n",
      "      Type                     File ID  Start Time  Duration STypeNew  \\\n",
      "0     Elan              biancak-a2-nsb     123.880     0.650     KCHI   \n",
      "1     Elan              biancak-a2-nsb     140.270     4.260     KCHI   \n",
      "2     Elan              biancak-a2-nsb     145.020     1.080     KCHI   \n",
      "3     Elan              biancak-a2-nsb     149.050     0.640     KCHI   \n",
      "4     Elan              biancak-a2-nsb     151.030     0.980     KCHI   \n",
      "...    ...                         ...         ...       ...      ...   \n",
      "6218  Diar  biancak-a2-nsb.diarization   14631.909     1.681   SPEECH   \n",
      "6219  Diar  biancak-a2-nsb.diarization   14632.010     1.660      CHI   \n",
      "6220  Diar  biancak-a2-nsb.diarization   14634.290     1.958      CHI   \n",
      "6221  Diar  biancak-a2-nsb.diarization   14634.493     1.799   SPEECH   \n",
      "6222  Diar  biancak-a2-nsb.diarization   14635.492     0.597     KCHI   \n",
      "\n",
      "      Channel  Ortho1  Ortho2   SType  Name1  Name2  \n",
      "0         NaN     NaN     NaN     NaN    NaN    NaN  \n",
      "1         NaN     NaN     NaN     NaN    NaN    NaN  \n",
      "2         NaN     NaN     NaN     NaN    NaN    NaN  \n",
      "3         NaN     NaN     NaN     NaN    NaN    NaN  \n",
      "4         NaN     NaN     NaN     NaN    NaN    NaN  \n",
      "...       ...     ...     ...     ...    ...    ...  \n",
      "6218      1.0     NaN     NaN  SPEECH    NaN    NaN  \n",
      "6219      1.0     NaN     NaN     CHI    NaN    NaN  \n",
      "6220      1.0     NaN     NaN     CHI    NaN    NaN  \n",
      "6221      1.0     NaN     NaN  SPEECH    NaN    NaN  \n",
      "6222      1.0     NaN     NaN    KCHI    NaN    NaN  \n",
      "\n",
      "[7069 rows x 11 columns]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "50f1217e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a12249c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pablo\\AppData\\Local\\Temp\\ipykernel_30828\\3335347668.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_rttm[\"Start Time\"] = pd.to_numeric(df_rttm[\"Start Time\"], errors=\"coerce\")\n",
      "C:\\Users\\pablo\\AppData\\Local\\Temp\\ipykernel_30828\\3335347668.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_rttm[\"Duration\"]  = pd.to_numeric(df_rttm[\"Duration\"],  errors=\"coerce\")\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3c6b8278",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97553feb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing intervals (15 blocks):  29%|██▉       | 51786/180000 [14:27<36:13, 58.99it/s]  "
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be93d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results.to_csv(f\"resultados/{name}/df_results_{name}.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e77d601",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_resultados= pd.read_csv(f\"resultados/{name}/df_results_{name}.csv\")\n",
    "df_resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b499cb56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir las etiquetas\n",
    "labels = ['KCHI', 'OCH', 'FEM', 'MAL']\n",
    "\n",
    "# Extraer las etiquetas verdaderas y predichas\n",
    "y_true = df_resultados[['Elan_KCHI', 'Elan_OCH', 'Elan_FEM', 'Elan_MAL']].values\n",
    "y_pred = df_resultados[['Diar_KCHI', 'Diar_OCH', 'Diar_FEM', 'Diar_MAL']].values\n",
    "\n",
    "# Calcular la matriz de confusión multilabel\n",
    "conf_matrix = multilabel_confusion_matrix(y_true, y_pred)\n",
    "\n",
    "# Mostrar la matriz de confusión para cada etiqueta\n",
    "for i, label in enumerate(labels):\n",
    "    print(f\"Matriz de confusión para la etiqueta {label}:\")\n",
    "    print(conf_matrix[i])\n",
    "    print()\n",
    "\n",
    "# Opcionalmente, puedes imprimir un informe de clasificación\n",
    "print(\"Informe de clasificación:\")\n",
    "print(classification_report(y_true, y_pred, target_names=labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac763d2e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Conversión de etiquetas multilabel a etiquetas de clase única (mismo código que antes)\n",
    "def multilabel_to_singlelabel(y_multilabel):\n",
    "    single_labels = []\n",
    "    for row in y_multilabel:\n",
    "        indices = np.where(row == 1)[0]\n",
    "        if len(indices) == 0:\n",
    "            single_labels.append(-1)  # Sin etiqueta\n",
    "        else:\n",
    "            # Si hay múltiples etiquetas, puedes decidir cómo manejarlas.\n",
    "            # Aquí, tomamos la primera etiqueta encontrada.\n",
    "            single_labels.append(indices[0])\n",
    "    return np.array(single_labels)\n",
    "\n",
    "y_true = multilabel_to_singlelabel(y_true)\n",
    "y_pred = multilabel_to_singlelabel(y_pred)\n",
    "\n",
    "# Filtrar las instancias sin etiqueta\n",
    "valid_indices = y_true != -1\n",
    "y_true = y_true[valid_indices]\n",
    "y_pred = y_pred[valid_indices]\n",
    "\n",
    "# Calcular la matriz de confusión normalizada\n",
    "cm = confusion_matrix(y_true, y_pred, labels=range(len(labels)), normalize='true')\n",
    "\n",
    "# Crear un DataFrame para la matriz de confusión\n",
    "cm_df = pd.DataFrame(cm, index=labels, columns=labels)\n",
    "\n",
    "# Crear las anotaciones con porcentajes\n",
    "annot = cm_df.applymap(lambda x: '{0:.1f}%'.format(x*100))\n",
    "\n",
    "\n",
    "# Crear el gráfico de la matriz de confusión con porcentajes\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(cm_df, annot=annot, fmt='', cmap='Blues', cbar_kws={'format': '%.0f%%'})\n",
    "plt.title('Matriz de Confusión Normalizada entre Elan y Diar')\n",
    "plt.ylabel('Etiquetas Verdaderas (Elan)')\n",
    "plt.xlabel('Etiquetas Predichas (Diar)')\n",
    "\n",
    "# Guardar la figura como un archivo PNG\n",
    "plt.savefig(f'resultados/{name}/matriz_confusion_{name}.png', dpi=300, bbox_inches='tight')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d7cca23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cálculo de precisión, recall y F1-score\n",
    "types = ['KCHI', 'OCH', 'FEM', 'MAL']\n",
    "\n",
    "# Inicializar listas para almacenar las métricas\n",
    "metrics = {\n",
    "    'Tipo': [],\n",
    "    'Precisión': [],\n",
    "    'Recall': [],\n",
    "    'F1-score': []\n",
    "}\n",
    "\n",
    "print(\"\\nCalculando métricas de precisión, recall y F1-score:\")\n",
    "for t in tqdm(types, desc=\"Procesando tipos\"):\n",
    "    y_true = df_results['Elan_' + t]\n",
    "    y_pred = df_results['Diar_' + t]\n",
    "    precision = precision_score(y_true, y_pred, zero_division=0)\n",
    "    recall = recall_score(y_true, y_pred, zero_division=0)\n",
    "    f1 = f1_score(y_true, y_pred, zero_division=0)\n",
    "    \n",
    "    # Almacenar las métricas\n",
    "    metrics['Tipo'].append(t)\n",
    "    metrics['Precisión'].append(precision)\n",
    "    metrics['Recall'].append(recall)\n",
    "    metrics['F1-score'].append(f1)\n",
    "    \n",
    "    # Imprimir los resultados\n",
    "    print(f\"\\nResultados para el tipo {t}:\")\n",
    "    print(f\"Precisión: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1-score: {f1:.4f}\")\n",
    "\n",
    "# Crear DataFrame de métricas\n",
    "df_metrics = pd.DataFrame(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f62353d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92377528",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b7d015",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Generar gráficos\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# Gráfico de barras para Precisión\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.barplot(x='Tipo', y='Precisión', data=df_metrics, palette='Blues_d')\n",
    "plt.title('Precisión por Tipo')\n",
    "plt.ylim(0, 1)\n",
    "plt.ylabel('Precisión')\n",
    "\n",
    "# Guardar la figura como un archivo PNG\n",
    "plt.savefig(f'resultados/{name}/precision_{name}.png', dpi=300, bbox_inches='tight')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Gráfico de barras para Recall\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.barplot(x='Tipo', y='Recall', data=df_metrics, palette='Greens_d')\n",
    "plt.title('Recall por Tipo')\n",
    "plt.ylim(0, 1)\n",
    "plt.ylabel('Recall')\n",
    "\n",
    "# Guardar la figura como un archivo PNG\n",
    "plt.savefig(f'resultados/{name}/recall_{name}.png', dpi=300, bbox_inches='tight')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Gráfico de barras para F1-score\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.barplot(x='Tipo', y='F1-score', data=df_metrics, palette='Reds_d')\n",
    "plt.title('F1-score por Tipo')\n",
    "plt.ylim(0, 1)\n",
    "plt.ylabel('F1-score')\n",
    "# Guardar la figura como un archivo PNG\n",
    "plt.savefig(f'resultados/{name}/f1score_{name}.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Gráfico combinado\n",
    "df_metrics_melted = pd.melt(df_metrics, id_vars=['Tipo'], value_vars=['Precisión', 'Recall', 'F1-score'], var_name='Métrica', value_name='Valor')\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x='Tipo', y='Valor', hue='Métrica', data=df_metrics_melted)\n",
    "plt.title('Métricas por Tipo')\n",
    "plt.ylim(0, 1)\n",
    "plt.ylabel('Valor')\n",
    "plt.legend(title='Métrica')\n",
    "\n",
    "# Guardar la figura como un archivo PNG\n",
    "plt.savefig(f'resultados/{name}/combinado_{name}.png', dpi=300, bbox_inches='tight')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f42df35b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "778dc6f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleccionar las columnas que empiezan con \"Diar_\"\n",
    "diar_columns = [col for col in df_resultados.columns if col.startswith('Diar_')]\n",
    "\n",
    "# Cambiar los valores de 1 a 0.8 en esas columnas\n",
    "df_resultados[diar_columns] = df_resultados[diar_columns].replace(1, 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde8a5b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir las columnas que deseas graficar\n",
    "columns_to_plot = ['Elan_FEM', 'Diar_FEM']\n",
    "\n",
    "# Definir colores contrastantes\n",
    "colors = ['#FF6347', '#4682B4']  # Tomato y SteelBlue\n",
    "\n",
    "# Crear la gráfica de dispersión para mostrar solo los estados sin transiciones\n",
    "plt.figure(figsize=(14, 8))\n",
    "\n",
    "# Graficar solo los puntos donde el valor es 1\n",
    "for i, column in enumerate(columns_to_plot):\n",
    "    plt.scatter(df_resultados.index, df_resultados[column], label=column, color=colors[i], s=10)\n",
    "\n",
    "# Configuración del gráfico\n",
    "plt.title('Estados de Elan_FEM y Diar_FEM')\n",
    "plt.xlabel('Tiempo [seg]')\n",
    "plt.ylabel('Valores Binarios')\n",
    "plt.legend(loc='upper right')\n",
    "plt.grid(True)\n",
    "plt.xlim(0, 30000)\n",
    "\n",
    "# Guardar la figura como un archivo PNG\n",
    "# plt.savefig(f'binarios_{name}.png', dpi=300, bbox_inches='tight')\n",
    "# Mostrar la gráfica\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07efd8ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir las columnas que deseas graficar\n",
    "columns_to_plot = ['Elan_FEM', 'Diar_FEM']\n",
    "\n",
    "# Definir colores contrastantes\n",
    "colors = ['#FF6347', '#4682B4']  # Tomato y SteelBlue\n",
    "\n",
    "# Crear la gráfica de dispersión para mostrar solo los estados sin transiciones\n",
    "plt.figure(figsize=(14, 8))\n",
    "\n",
    "# Graficar solo los puntos donde el valor es 1\n",
    "for i, column in enumerate(columns_to_plot):\n",
    "    plt.scatter(df_resultados.index, df_resultados[column], label=column, color=colors[i], s=10)\n",
    "\n",
    "# Configuración del gráfico\n",
    "plt.title('Estados de Elan_FEM y Diar_FEM')\n",
    "plt.xlabel('Tiempo [seg]')\n",
    "plt.ylabel('Valores Binarios')\n",
    "plt.legend(loc='upper right')\n",
    "plt.grid(True)\n",
    "plt.xlim(1000, 1400)\n",
    "\n",
    "# Guardar la figura como un archivo PNG\n",
    "# plt.savefig(f'binariosShort_{name}.png', dpi=300, bbox_inches='tight')\n",
    "\n",
    "# Mostrar la gráfica\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d7539d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdedd086",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd94279",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e9acb7a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
